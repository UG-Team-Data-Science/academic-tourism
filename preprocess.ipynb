{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708c9d9bffa4481eb0c6df93d0d608ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/5.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454806889e694b09aea3f444c450b7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/855M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da5463e53a1426da6e1cd8b6ff4943d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb4d331ab88440ab562044cd390fd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/855M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a247c770937443faf3045044d7e6047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "head_config.json:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4691b18b8a4dce90478aa5405a4311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_adapter.bin:   0%|          | 0.00/1.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4a254be5a445ddb2ecf894e77b4306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model_head.bin:   0%|          | 0.00/343k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "from wtpsplit import SaT\n",
    "\n",
    "sat = SaT(\"sat-3l\", language=\"nl\", style_or_domain=\"ud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "doc = Document(\"data/Ontology-based Annotation.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s for p in doc.paragraphs for s in sat.split(p.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilhelmshöhe (E53 Place), voorheen Weissenstein (E53 Place) genoemd en ook reeds een blaauwe maandag Napoleonshöhe (E53 Place) geheten, is een lustplaats aan den Keurvorst van Hessen Cassel (E21 Person) toebehorende een groot uur (E52 Time-Span) van de stad gelegen: de landgraven Karel (E21 Person) en Frederik de II (E21 Person) hebben hetzelve begonnen & het is op eene heerlyke wyze door den thans regeerende Keurvorst Willem de IX (E21 Person) voltooid geworden. Even als ik reeds meermalen gedaan heb zal ik u maar alles in die orde mededeelen als het ons is voorgekomen. Langs eene lange breede laan gingen wy Zondag ll (E52 Time-Span) naar het zoo beroemde Weissenstein (E53 Place) en wel op dien dag omdat alle waterwerken dan in beweging zyn hetgeen men niet dan met groote moeite op andere dagen gedaan kan krygen waarby men dan toch altyd het groote gewoel der wandelaars zoo wel inwoners der stad als vreemdelingen mist. Op eenige afstand der stad gekomen zagen wy regts af de enorme Casernes (E19 Physical Thing) door Jerome (E21 Person) in zyne tyd gebouwd waar verscheiden duizend man, ja volgens het zeggen van iemand, ’t geen my echter onwaarschynlyk voorkomt, wel 30,000 man (E54 Dimension) in geborgen kunnen worden: deeze linden allee is aan weerszyde met huizen bezet waaronder eenige zeer goede en enkele mooye tuinhuizen; \n"
     ]
    }
   ],
   "source": [
    "test_paragraph = doc.paragraphs[3]\n",
    "print(test_paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Entity:\n",
    "    label: str\n",
    "    span: Tuple[int, int]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AnnotatedText:\n",
    "    text: str\n",
    "    entities: List[Entity]\n",
    "\n",
    "\n",
    "def annotations_from_paragraph(paragraph) -> AnnotatedText:\n",
    "    clean_text = \"\"\n",
    "    entities = []\n",
    "\n",
    "    # Track positions\n",
    "    clean_position = 0\n",
    "\n",
    "    # Track entity building state\n",
    "    current_entity_text = \"\"\n",
    "    current_entity_start = None\n",
    "    in_entity = False\n",
    "    in_label = False\n",
    "    label_buffer = \"\"\n",
    "\n",
    "    for run in paragraph.runs:\n",
    "        text = run.text\n",
    "\n",
    "        if in_label:\n",
    "            # We're in the middle of collecting a label\n",
    "            closing_paren_pos = text.find(\")\")\n",
    "            if closing_paren_pos != -1:\n",
    "                # Found the end of the label\n",
    "                label_buffer += text[: closing_paren_pos + 1]\n",
    "                label = label_buffer[\n",
    "                    label_buffer.find(\"(\") + 1 : label_buffer.find(\")\")\n",
    "                ]\n",
    "                if current_entity_text:  # Only add if we have an entity\n",
    "                    entities.append(\n",
    "                        Entity(label=label, span=(current_entity_start, clean_position))\n",
    "                    )\n",
    "\n",
    "                # Reset states\n",
    "                current_entity_text = \"\"\n",
    "                current_entity_start = None\n",
    "                in_entity = False\n",
    "                in_label = False\n",
    "                label_buffer = \"\"\n",
    "\n",
    "                # Add any remaining text after the label\n",
    "                remaining_text = text[closing_paren_pos + 1 :]\n",
    "                if remaining_text:\n",
    "                    clean_text += remaining_text\n",
    "                    clean_position += len(remaining_text)\n",
    "            else:\n",
    "                # Still collecting label\n",
    "                label_buffer += text\n",
    "        else:\n",
    "            # Not in label - check if this run starts a label\n",
    "            opening_paren_pos = text.find(\"(\")\n",
    "\n",
    "            if opening_paren_pos != -1:\n",
    "                # Found start of label\n",
    "                # First add any text before the label if not in entity\n",
    "                if not in_entity and opening_paren_pos > 0:\n",
    "                    prefix_text = text[:opening_paren_pos]\n",
    "                    clean_text += prefix_text\n",
    "                    clean_position += len(prefix_text)\n",
    "\n",
    "                in_label = True\n",
    "                label_buffer = text[opening_paren_pos:]\n",
    "\n",
    "                # Check if label ends in this same run\n",
    "                closing_paren_pos = text.find(\")\", opening_paren_pos)\n",
    "                if closing_paren_pos != -1:\n",
    "                    label = text[opening_paren_pos + 1 : closing_paren_pos]\n",
    "                    if current_entity_text:  # Only add if we have an entity\n",
    "                        entities.append(\n",
    "                            Entity(\n",
    "                                label=label, span=(current_entity_start, clean_position)\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    # Reset states\n",
    "                    current_entity_text = \"\"\n",
    "                    current_entity_start = None\n",
    "                    in_entity = False\n",
    "                    in_label = False\n",
    "                    label_buffer = \"\"\n",
    "\n",
    "                    # Add any remaining text after the label\n",
    "                    remaining_text = text[closing_paren_pos + 1 :]\n",
    "                    if remaining_text:\n",
    "                        clean_text += remaining_text\n",
    "                        clean_position += len(remaining_text)\n",
    "\n",
    "            elif run.bold and not in_entity:\n",
    "                # Start of new entity\n",
    "                current_entity_start = clean_position\n",
    "                in_entity = True\n",
    "                current_entity_text += text\n",
    "                clean_text += text\n",
    "                clean_position += len(text)\n",
    "\n",
    "            elif run.bold and in_entity:\n",
    "                # Continuation of entity\n",
    "                current_entity_text += text\n",
    "                clean_text += text\n",
    "                clean_position += len(text)\n",
    "\n",
    "            elif text.strip() == \"\":\n",
    "                # Whitespace - include if in entity\n",
    "                if in_entity:\n",
    "                    current_entity_text += text\n",
    "                    clean_text += text\n",
    "                    clean_position += len(text)\n",
    "                else:\n",
    "                    clean_text += text\n",
    "                    clean_position += len(text)\n",
    "            else:\n",
    "                # Regular text\n",
    "                if in_entity:\n",
    "                    # We were collecting an entity but found non-label text\n",
    "                    in_entity = False\n",
    "                    current_entity_text = \"\"\n",
    "                    current_entity_start = None\n",
    "                clean_text += text\n",
    "                clean_position += len(text)\n",
    "    return AnnotatedText(clean_text, entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DemoExample(text='Wilhelmshöhe, voorheen Weissenstein genoemd en ook reeds een blaauwe maandag Napoleonshöhe geheten, is een lustplaats aan den Keurvorst van Hessen Cassel toebehorende een groot uur van de stad gelegen: ', labels=[DemoLabel(span='Wilhelmshöhe', types=['E53 Place']), DemoLabel(span='Weissenstein', types=['E53 Place']), DemoLabel(span='Napoleonshöhe', types=['E53 Place']), DemoLabel(span='Keurvorst van Hessen Cassel', types=['E21 Person']), DemoLabel(span='groot uur', types=['E52 Time-Span'])], source=''),\n",
       " DemoExample(text='de landgraven Karel en Frederik de II hebben hetzelve begonnen & het is op eene heerlyke wyze door den thans regeerende Keurvorst Willem de IX voltooid geworden. ', labels=[DemoLabel(span='Karel', types=['E21 Person']), DemoLabel(span='Frederik de II', types=['E21 Person']), DemoLabel(span='Keurvorst Willem de IX', types=['E21 Person'])], source=''),\n",
       " DemoExample(text='Even als ik reeds meermalen gedaan heb zal ik u maar alles in die orde mededeelen als het ons is voorgekomen. ', labels=[], source=''),\n",
       " DemoExample(text='Langs eene lange breede laan gingen wy Zondag ll  naar het zoo beroemde Weissenstein en wel op dien dag omdat alle waterwerken dan in beweging zyn hetgeen men niet dan met groote moeite op andere dagen gedaan kan krygen waarby men dan toch altyd het groote gewoel der wandelaars zoo wel inwoners der stad als vreemdelingen mist. ', labels=[DemoLabel(span='Zondag ll', types=['E52 Time-Span']), DemoLabel(span='Weissenstein', types=['E53 Place'])], source=''),\n",
       " DemoExample(text='Op eenige afstand der stad gekomen zagen wy regts af de enorme Casernes  door Jerome in zyne tyd gebouwd waar verscheiden duizend man, ja volgens het zeggen van iemand, ’t geen my echter onwaarschynlyk voorkomt, wel 30,000 man  in geborgen kunnen worden: deeze linden allee is aan weerszyde met huizen bezet waaronder eenige zeer goede en enkele mooye tuinhuizen; ', labels=[DemoLabel(span='Casernes', types=['E19 Physical Thing']), DemoLabel(span='Jerome', types=['E21 Person'])], source='')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def get_sentence_boundaries(text: str, sentences: list[str]) -> list[int]:\n",
    "    sentence_boundaries = []\n",
    "    current_start = 0\n",
    "\n",
    "    for i, sent in enumerate(sentences):\n",
    "        sentence_boundaries.append((current_start, current_start + len(sent)))\n",
    "        current_start += len(sent)\n",
    "\n",
    "    return sentence_boundaries\n",
    "\n",
    "\n",
    "def split_into_sentences_with_entities(\n",
    "    original_text: str, sentences: list[str], entities: list[Entity]\n",
    ") -> list[tuple[str, list[Entity]]]:\n",
    "    sentence_boundaries = get_sentence_boundaries(original_text, sentences)\n",
    "\n",
    "    result = []\n",
    "    for sent, (sent_start, sent_end) in zip(sentences, sentence_boundaries):\n",
    "        sent_entities = []\n",
    "\n",
    "        for entity in entities:\n",
    "            # Get the new positions for this entity\n",
    "            ent_start = entity.span[0]\n",
    "            ent_end = entity.span[1]\n",
    "\n",
    "            # Check if the entity belongs to this sentence\n",
    "            if (\n",
    "                (ent_start >= sent_start and ent_start < sent_end)\n",
    "                or (ent_end > sent_start and ent_end <= sent_end)\n",
    "                or (ent_start <= sent_start and ent_end >= sent_end)\n",
    "            ):\n",
    "                # Adjust spans to be relative to sentence start\n",
    "                adjusted_start = max(0, ent_start - sent_start)\n",
    "                adjusted_end = min(len(sent), ent_end - sent_start)\n",
    "\n",
    "                # Only add if there's actually an overlap\n",
    "                if adjusted_end > adjusted_start:\n",
    "                    sent_entities.append(\n",
    "                        Entity(label=entity.label, span=(adjusted_start, adjusted_end))\n",
    "                    )\n",
    "        result.append((sent, sent_entities))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DemoLabel:\n",
    "    span: str\n",
    "    types: list[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DemoExample:\n",
    "    text: str\n",
    "    labels: list[DemoLabel]\n",
    "    source: str\n",
    "\n",
    "\n",
    "def format_example(sentence: str, entities: list[Entity], source: str) -> DemoExample:\n",
    "    labels = [\n",
    "        DemoLabel(\n",
    "            types=[lab.strip() for lab in ent.label.split(\",\")],\n",
    "            span=sentence[ent.span[0] : ent.span[1]].strip(),\n",
    "        )\n",
    "        for ent in entities\n",
    "    ]\n",
    "    return DemoExample(text=sentence, labels=labels, source=source)\n",
    "\n",
    "\n",
    "annotated_paragraph = annotations_from_paragraph(test_paragraph)\n",
    "sentences = [s for s in sat.split(annotated_paragraph.text)]\n",
    "sentences_with_entities = split_into_sentences_with_entities(\n",
    "    annotated_paragraph.text, sentences, annotated_paragraph.entities\n",
    ")\n",
    "[format_example(sent, ents, \"\") for sent, ents in sentences_with_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "datadir = Path(\"data\")\n",
    "input_files = datadir.glob(\"*.docx\")\n",
    "\n",
    "demo_examples = []\n",
    "\n",
    "for file in input_files:\n",
    "    doc = Document(file)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        annotated_paragraph = annotations_from_paragraph(paragraph)\n",
    "        sentences = [s for s in sat.split(annotated_paragraph.text)]\n",
    "        sentences_with_entities = split_into_sentences_with_entities(\n",
    "            annotated_paragraph.text, sentences, annotated_paragraph.entities\n",
    "        )\n",
    "        demo_examples += [\n",
    "            format_example(sent, ents, str(file.relative_to(datadir)))\n",
    "            for sent, ents in sentences_with_entities\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with datadir.joinpath(\"examples_to_clean.jsonl\").open(\n",
    "    \"w\", encoding=\"utf-8\"\n",
    ") as f:\n",
    "    for ex in demo_examples:\n",
    "        f.write(json.dumps(asdict(ex), ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/examples_to_clean.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
